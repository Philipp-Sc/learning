/*

add avg rating point gained to evaluation display
add avg time spent on move

- Open File x
- Half Open File x
- Isolated Pawn x
- Double pawn x
- King Side Pawn Majority x
- Queen Side Pawn Majority x
- Furthest advanced pawn
- Least advanced pawn
- Average pawn advancement
- Median pawn advancement
- Backward pawn
- Fianchetto
- Pinned Pieces 
- Outposts
- Center influence
- Over protection
- King safety

https://www.chessprogramming.org/Evaluation


- Add all the features
- possibly investigate random forest
- Do PCR Analysis on the feature, take explain 90%
- (cleans the feature vector)


- Make a regression analysis with all stats and the evaluation. To find out the most relevant features.


*/
 
    // load  engine database. for every game transform it to a list of FENs
    // also transform pgn to a list of moves that show which piece is captured by which
    // count P or p
    // count B or b
    // count N or n
    // count Q or q
    // count R or r
    // transform FEN to boolean board free/not free square, check free lines 
    // # Nx, Bx, Rx, Qx, Kx, [a-g]x
    // perc of possible (B x n, N x b, BxB, NxN) exchanges count(has possible exchange) vs actual
    // percentage of influence
    // perc. castled by now

    // outward influence of bishops and knights (with pawns)
    // remove all other own pieces except pawns and king, count number of moves.

    //1) Material (xx)
    //2) Mobility (xx) (pawn mobility, piece mobility, queen mobility)
    //3) Expansion factor. (global,queenside,kingside)
    // expansion factor only pawns
    //4) Packing density. (x) == fire power
    //5) Integrety 

    // what are the lead ups likelyhoods to forec zugzwang
    // given all previous positions p with the error[a_prev-a_now] at @depth
    // integrety is the variance of the errors
    // low variance == high integrety

    // chaos 


    
/*<IonBadge>Elo: {playerElo}</IonBadge>*/



async function createAutoencoder(latent_features,inputSize){
    const model = tf.sequential();
  
    // To simulate PCA we use 1 hidden layer with a linear (relu) activation
    const encoder = tf.layers.dense({
      units: latent_features, 
      batchInputShape:[null,inputSize],          //We will input N samples X 4 columns
      activation: 'relu',
      kernelInitializer:"randomNormal",  //Randomize to avoid degenerate cases
      biasInitializer:"ones"});
    const decoder = tf.layers.dense({units: inputSize, activation: 'relu'});

    model.add(encoder);
    model.add(decoder); 
    await model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});
    
    return  {
      'model':model,
      'encoder':encoder,
      'decoder':decoder
    }
}

async function trainAutoencoder(inputData,autoencoder) {
    const xs = tf.tensor2d(inputData);
    let h = await autoencoder.model.fit(xs, xs, {epochs: 5,batchSize:15,shuffle:true,validationSpit:0.1,
        callbacks: tfvis.show.fitCallbacks(
      { name: 'Training Autoencoder Performance' },
      ['loss', 'mse'],
      { height: 300, callbacks: ['onEpochEnd'] }
    )});
    xs.dispose();
    return h;
}

function getEuclidianDistance(arr1, arr2) {
        // calculate euclidian distance between two arrays
        let distTensor = tf.tidy(() => {
            const distance = tf.squaredDifference(arr1, arr2).sum().sqrt();
            return distance.dataSync()
        })
        return distTensor[0];
}// use this to only provide novel vectors to train.
